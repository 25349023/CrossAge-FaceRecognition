{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import Matrix\n",
    "from ModelFactory import model_insightface\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dataloader.dataset import CALFWDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ModelFactory.model_insightface' from 'c:\\\\Users\\\\Ben\\\\Documents\\\\cv_final\\\\CV-Final-FaceRecognition\\\\BaselineScript\\\\ModelFactory\\\\model_insightface.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(model_insightface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "class FileDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.id2fn = []\n",
    "        self.fn2id = {}\n",
    "\n",
    "        files = os.listdir(root)\n",
    "\n",
    "        for f in files:\n",
    "            self.fn2id[f] = len(self.id2fn)\n",
    "            self.id2fn.append(f)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = Image.open(os.path.join(self.root, self.id2fn[item]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id2fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_insightface.MobileFaceNet(512).to('cuda').eval()\n",
    "model.load_state_dict(torch.load('./Model/model_mobilefacenet.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_insightface.GroupMobileFaceNet(512).to('cuda').eval()\n",
    "model.load_state_dict(torch.load('ckpt/model-best_gp_11.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "dataset = FileDataset(\n",
    "    '../data/calfw/FGNet_500/',\n",
    "    transform=T.Compose([T.Resize(112), T.ToTensor(), normalization]))\n",
    "dataloader = DataLoader(dataset, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    features = []\n",
    "    for i, pics in enumerate(tqdm.tqdm(dataloader, file=sys.stdout, desc='Evaluating: ', leave=False)):\n",
    "        pics = pics.to('cuda')\n",
    "        features.append(model(pics))\n",
    "    features = torch.cat(features, dim=0).cpu()\n",
    "\n",
    "pd_pair = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    pd_pair.append(Matrix.get_cosine_similarity(features[i:i + 1], features[i + 1:])[0])\n",
    "\n",
    "pd_table = torch.zeros((len(dataset), len(dataset)))\n",
    "\n",
    "for i, vec in enumerate(pd_pair):\n",
    "    pd_table[i, i+1:] = vec\n",
    "    pd_table[i+1:, i] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pairs = []\n",
    "fn2id = dataset.fn2id\n",
    "with open('../data/calfw/ForTesting/Test_PairList.csv',\n",
    "                'r', encoding='utf-8', newline='') as f:\n",
    "    for fn1, fn2 in csv.reader(f):\n",
    "        file_pairs.append((fn2id[fn1], fn2id[fn2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Test_team08_results.csv',\n",
    "                'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for (id1, id2) in file_pairs:\n",
    "        writer.writerow([pd_table[id1][id2].item()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "dataset = FileDataset(\n",
    "    '../data/calfw/ForGrouping/',\n",
    "    transform=T.Compose([T.Resize(112), T.ToTensor(), normalization]))\n",
    "dataloader = DataLoader(dataset, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    features = []\n",
    "    for i, pics in enumerate(tqdm.tqdm(dataloader, file=sys.stdout, desc='Evaluating: ', leave=False)):\n",
    "        pics = pics.to('cuda')\n",
    "        features.append(model(pics))\n",
    "    features = torch.cat(features, dim=0).cpu()\n",
    "\n",
    "pd_pair = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    pd_pair.append(Matrix.get_cosine_similarity(features[i:i + 1], features[i + 1:])[0])\n",
    "\n",
    "pd_table = torch.zeros((len(dataset), len(dataset)))\n",
    "\n",
    "for i, vec in enumerate(pd_pair):\n",
    "    pd_table[i, i+1:] = vec\n",
    "    pd_table[i+1:, i] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = torch.zeros((len(dataset)))\n",
    "used = torch.zeros((len(dataset)), dtype=torch.bool)\n",
    "\n",
    "for i in range(20):\n",
    "    dist = None\n",
    "    for j in range(len(used)):\n",
    "        if used[j]:\n",
    "            continue\n",
    "        target_id = j\n",
    "        dist = pd_table[i, :]\n",
    "        used[j] = True\n",
    "        group[j] = i\n",
    "        break\n",
    "    if dist == None:\n",
    "        print(\"error\")\n",
    "    dist[used] = -2\n",
    "    for _ in range(1, 6):\n",
    "        target_id = torch.argmax(dist)\n",
    "        dist = torch.max(torch.stack([pd_table[i, :], dist], dim=0), dim=0)[0]\n",
    "        used[target_id] = True\n",
    "        dist[used] = -2\n",
    "        group[target_id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "         14., 15., 16., 17., 18., 19.]),\n",
       " tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(group, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order = []\n",
    "fn2id = dataset.fn2id\n",
    "with open('../data/calfw/ForTesting/Test_BonusList.csv',\n",
    "                'r', encoding='utf-8', newline='') as f:\n",
    "    for [fn] in csv.reader(f):\n",
    "        file_order.append(fn2id[fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Test_team08_bonus_results.csv',\n",
    "                'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for id in file_order:\n",
    "        writer.writerow([group[id].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91c1d2470ab80b393afef1a9308e4146ea19685bf186cfe44fe3659b7d9e4fc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
